{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894e8677",
   "metadata": {},
   "source": [
    "### üìå Ti√™u ch√≠ c·∫ßn ƒë√°p ·ª©ng"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5d0a578",
   "metadata": {},
   "source": [
    "*Python version 3.9\n",
    "\n",
    "*C√†i s·∫µn file th∆∞ vi·ªán Dlib t∆∞∆°ng ·ª©ng v·ªõi phi√™n b·∫£n python (vd: py ver 3.9 <=> cp39 ):dlib-19.22.99-cp39-cp39-win_amd64.whl\n",
    "\n",
    "*C√†i s·∫µn 2 file m√¥ h√¨nh pre-trained c·ªßa Dlib gi√∫p nh·∫≠n di·ªán khu√¥n m·∫∑t: dlib_face_recognition_resnet_model_v1.dat || shape_predictor_68_face_landmarks.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2dddf",
   "metadata": {},
   "source": [
    "### üîßC√†i th∆∞ vi·ªán dlib t·ª´ file.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601bbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\acer\\baitaploncv\\dlib-19.22.99-cp39-cp39-win_amd64.whl\n",
      "dlib is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dlib-19.22.99-cp39-cp39-win_amd64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfa0f88",
   "metadata": {},
   "source": [
    "### üîç Khai b√°o th∆∞ vi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2615ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780f4dc",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Thu th·∫≠p d·ªØ li·ªáu (n ·∫£nh t·ª´ camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c76a21",
   "metadata": {},
   "source": [
    "1.1. Kh·ªüi t·∫°o detector HOG c·ªßa Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4855ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a2ae1",
   "metadata": {},
   "source": [
    "1.2. Ch·ªânh s·ª≠a th∆∞ m·ª•c l∆∞u ·∫£nh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0b6def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê∆∞·ªùng d·∫´n ·∫£nh: data/tuan anh/\n"
     ]
    }
   ],
   "source": [
    "person_name = \"tuan anh\"  # ƒê·ªïi t√™n theo ng∆∞·ªùi(vi·∫øt kh√¥ng d·∫•u)\n",
    "output_dir = f\"data/{person_name}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print('ƒê∆∞·ªùng d·∫´n ·∫£nh: ' + output_dir + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4d56e",
   "metadata": {},
   "source": [
    "1.3. ƒêi·ªÅu ch·ªânh c√°ch th·ª©c l·∫•y ·∫£nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60f51158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng ·∫£nh c·∫ßn thu th·∫≠p: 200 ·∫£nh\n"
     ]
    }
   ],
   "source": [
    "img_count = 0 \n",
    "MAX_IMAGES = 200 # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ·∫£nh c·∫ßn l·∫•y\n",
    "\n",
    "print(f'S·ªë l∆∞·ª£ng ·∫£nh c·∫ßn thu th·∫≠p: {MAX_IMAGES} ·∫£nh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0134ee",
   "metadata": {},
   "source": [
    "1.4. B·∫Øt ƒë·∫ßu thu th·∫≠p ·∫£nh (m·ªü camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ec8e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥B·∫Øt ƒë·∫ßu thu th·∫≠p ·∫£nh...\n",
      "‚úÖThu th·∫≠p ·∫£nh ho√†n t·∫•t\n"
     ]
    }
   ],
   "source": [
    "print('‚è≥B·∫Øt ƒë·∫ßu thu th·∫≠p ·∫£nh...')\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for i, face in enumerate(faces):\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        # C·∫Øt khu√¥n m·∫∑t\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        face_img = cv2.resize(face_img, (150, 150))\n",
    "        img_path = f\"{output_dir}/{person_name}_{img_count}.jpg\"\n",
    "        cv2.imwrite(img_path, face_img)\n",
    "        img_count += 1\n",
    "\n",
    "        # V·∫Ω h√¨nh ch·ªØ nh·∫≠t quanh m·∫∑t\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Dang tu dong thu thap du lieu - Nhan ESC de dung luu/thoat\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27 or img_count >= MAX_IMAGES:  # B·∫•m ESC ƒë·ªÉ tho√°t\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('‚úÖThu th·∫≠p ·∫£nh ho√†n t·∫•t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8002957",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG + 128D embedding & g√°n nh√£n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba5e39",
   "metadata": {},
   "source": [
    "2.1. Load models c·ªßa Dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0712ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖHo√†n t·∫Øt load models\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "# D·ª± ƒëo√°n 68 ƒëi·ªÉm (shape_predictor)\n",
    "sp = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # c·∫ßn t·∫£i tr∆∞·ªõc\n",
    "# Tr√≠ch xu·∫•t vector 128D (resnet)\n",
    "facerec = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")  # c·∫ßn t·∫£i tr∆∞·ªõc\n",
    "\n",
    "print('‚úÖHo√†n t·∫Øt load models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f39f4b",
   "metadata": {},
   "source": [
    "2.2. Duy·ªát qua th∆∞ m·ª•c dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c09a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...\n",
      "‚úÖHo√†n t·∫•t duy·ªát d·ªØ li·ªáu\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"data\"\n",
    "embeddings = []\n",
    "labels = []\n",
    "print('‚è≥ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...')\n",
    "for person_name in os.listdir(dataset_path):\n",
    "    person_path = os.path.join(dataset_path, person_name)\n",
    "    for img_path in paths.list_images(person_path):\n",
    "        image = cv2.imread(img_path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        if len(faces) != 1:\n",
    "            continue  # b·ªè qua ·∫£nh kh√¥ng r√µ m·∫∑t\n",
    "\n",
    "        shape = sp(gray, faces[0]) # D·ª± ƒëo√°n 68 ƒëi·ªÉm (shape_predictor)\n",
    "        face_descriptor = facerec.compute_face_descriptor(image, shape) # Tr√≠ch xu·∫•t vector 128D (resnet)\n",
    "        embeddings.append(np.array(face_descriptor))\n",
    "        labels.append(person_name)\n",
    "\n",
    "print('‚úÖHo√†n t·∫•t duy·ªát d·ªØ li·ªáu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605aeaf7",
   "metadata": {},
   "source": [
    "2.3. L∆∞u d·ªØ li·ªáu hu·∫•n luy·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cb3fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖƒê√£ l∆∞u xong ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t v√† nh√£n!\n"
     ]
    }
   ],
   "source": [
    "np.save(\"face_embeddings.npy\", embeddings)\n",
    "np.save(\"face_labels.npy\", labels)\n",
    "\n",
    "print(\"‚úÖƒê√£ l∆∞u xong ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t v√† nh√£n!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d63c10",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Nh·∫≠n di·ªán khu√¥n m·∫∑t realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1bddbc",
   "metadata": {},
   "source": [
    "3.1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8962e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖHo√†n t·∫•t load model\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "facerec = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")\n",
    "\n",
    "print(\"‚úÖHo√†n t·∫•t load model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ff2376",
   "metadata": {},
   "source": [
    "3.2. Load d·ªØ li·ªáu ƒë√£ hu·∫•n luy·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa021b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖHo√†n t·∫•t load d·ªØ li·ªáu train\n"
     ]
    }
   ],
   "source": [
    "known_embeddings = np.load(\"face_embeddings.npy\")\n",
    "known_labels = np.load(\"face_labels.npy\", allow_pickle=True)\n",
    "\n",
    "print(\"‚úÖHo√†n t·∫•t load d·ªØ li·ªáu train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd96e1b",
   "metadata": {},
   "source": [
    "3.3. H√†m t√≠nh kho·∫£ng c√°ch Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e624a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H√†m t√≠nh kho·∫£ng c√°ch ng∆∞·ª°ng: 0.6\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "# Ng∆∞·ª°ng kho·∫£ng c√°ch: d∆∞·ªõi ng∆∞·ª°ng l√† ƒë√∫ng ng∆∞·ªùi (t√πy ch·ªânh n·∫øu c·∫ßn)\n",
    "THRESHOLD = 0.6\n",
    "\n",
    "print(f'H√†m t√≠nh kho·∫£ng c√°ch ng∆∞·ª°ng: {THRESHOLD}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c042a22",
   "metadata": {},
   "source": [
    "3.4 T√πy ch·ªânh camera, log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f5fbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o m√†u khung\n",
    "fixed_colors = [\n",
    "    (0, 0, 255),     # Xanh d∆∞∆°ng\n",
    "    (255, 0, 0),     # ƒê·ªè\n",
    "    (0, 255, 0),     # Xanh l√°\n",
    "    (255, 255, 0),   # V√†ng\n",
    "    (128, 0, 128),   # T√≠m\n",
    "    (0, 0, 0),   # ƒêen\n",
    "    (255, 255, 255),   # Tr·∫Øng\n",
    "]\n",
    "color_map = {}\n",
    "def get_fixed_color(name):\n",
    "    if name not in color_map:\n",
    "        idx = len(color_map) % len(fixed_colors)\n",
    "        color_map[name] = fixed_colors[idx]\n",
    "    return color_map[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f605b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch·ªânh fps\n",
    "target_fps = 15\n",
    "frame_duration = 1.0 / target_fps\n",
    "prev_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca8689de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File log ƒë·ªÉ ghi l·∫°i ng∆∞·ªùi ƒë√£ xu·∫•t hi·ªán\n",
    "log_file = \"detected_people.log\"\n",
    "last_log_time = time.time()  # L·∫ßn ghi log cu·ªëi c√πng (ban ƒë·∫ßu l√† th·ªùi gian hi·ªán t·∫°i)\n",
    "\n",
    "def log_person(name):\n",
    "    global last_log_time  # D√πng bi·∫øn to√†n c·ª•c ƒë·ªÉ theo d√µi th·ªùi gian cu·ªëi c√πng ghi log\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Ki·ªÉm tra n·∫øu ƒë√£ ƒë·ªß 3 gi√¢y k·ªÉ t·ª´ l·∫ßn ghi log cu·ªëi\n",
    "    if current_time - last_log_time >= 3:\n",
    "        # Ghi log\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as file:\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "            file.write(f\"{timestamp} - {name} ƒë√£ xu·∫•t hi·ªán\\n\")\n",
    "        \n",
    "        last_log_time = current_time  # C·∫≠p nh·∫≠t th·ªùi gian ghi log l·∫ßn cu·ªëi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afd120fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay UI\n",
    "\n",
    "# def draw_ui_overlay(frame, fps, names_in_frame, log_status):\n",
    "#     height, width = frame.shape[:2]\n",
    "#     cv2.rectangle(frame, (0, 0), (width, 100), (0, 0, 0), -1)\n",
    "#     cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "#     cv2.putText(frame, f\"People: {len(names_in_frame)}\", (150, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "#     names_text = \", \".join(names_in_frame)\n",
    "#     cv2.putText(frame, f\"Names: {names_text}\", (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "#     cv2.putText(frame, f\"Log: {log_status}\", (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (100, 255, 255), 2)\n",
    "#     if \"Unknown\" in names_in_frame:\n",
    "#         cv2.putText(frame, \"‚ö†Ô∏è WARNING: Unknown Face!\", (width - 300, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f1426",
   "metadata": {},
   "source": [
    "3.4. B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t (m·ªü camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "468776fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t...\n",
      "‚úÖHo√†n t·∫•t nh·∫≠n di·ªán khu√¥n m·∫∑t!\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán khu√¥n m·∫∑t...\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    now = time.time()\n",
    "    elapsed = now - prev_time\n",
    "\n",
    "    if elapsed < frame_duration:\n",
    "        continue  # Ch·ªù n·∫øu ch∆∞a ƒë·∫øn th·ªùi gian cho frame ti·∫øp theo\n",
    "\n",
    "    prev_time = now\n",
    "    fps = 1.0 / elapsed\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "#     names_in_frame = []\n",
    "\n",
    "    for face in faces:\n",
    "        shape = sp(gray, face)\n",
    "        face_descriptor = facerec.compute_face_descriptor(frame, shape)\n",
    "        face_embedding = np.array(face_descriptor)\n",
    "\n",
    "        # So kh·ªõp v·ªõi d·ªØ li·ªáu ƒë√£ bi·∫øt\n",
    "        distances = [euclidean_distance(face_embedding, emb) for emb in known_embeddings]\n",
    "        min_dist = min(distances)\n",
    "        min_index = distances.index(min_dist)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "        if min_dist < THRESHOLD:\n",
    "            name = known_labels[min_index]\n",
    "\n",
    "        # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        color = get_fixed_color(name)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(frame, f\"{name} ({min_dist:.2f})\", (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "        # Ghi log ng∆∞·ªùi xu·∫•t hi·ªán\n",
    "        log_person(name)\n",
    "#         names_in_frame.append(name)\n",
    "        # V·∫Ω FPS l√™n ·∫£nh\n",
    "        fps_text = f\"FPS: {fps:.2f}\"\n",
    "        cv2.putText(frame, fps_text, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         fps = 1 / (end_time - start_time)\n",
    "#         start_time = end_time\n",
    "#         draw_ui_overlay(frame, fps, names_in_frame, \"‚úì ƒê√£ ghi log\")\n",
    "\n",
    "    cv2.imshow(\"Nhan dien khuon mat bang Dlib/HoG - Nhan ESC de thoat\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "    elif key == ord('n'):\n",
    "        # Nh·∫≠p t√™n\n",
    "        person_name = input(\"Nh·∫≠p t√™n ng∆∞·ªùi m·ªõi: \")\n",
    "\n",
    "        # T·∫°o th∆∞ m·ª•c ·∫£nh n·∫øu c·∫ßn\n",
    "        os.makedirs(f'dataset/{person_name}', exist_ok=True)\n",
    "\n",
    "        # Thu th·∫≠p 20 ·∫£nh\n",
    "        for i in range(20):\n",
    "            ret, frame = cap.read()\n",
    "            faces = detector(frame)\n",
    "            for face in faces:\n",
    "                shape = sp(frame, face)\n",
    "                face_img = frame[face.top():face.bottom(), face.left():face.right()]\n",
    "                cv2.imwrite(f'dataset/{person_name}/{person_name}_{i}.jpg', face_img)\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        # Tr√≠ch xu·∫•t vector 128D cho t·ª´ng ·∫£nh\n",
    "        for img_file in os.listdir(f'dataset/{person_name}'):\n",
    "            img = cv2.imread(f'dataset/{person_name}/{img_file}')\n",
    "            dets = detector(img)\n",
    "            for det in dets:\n",
    "                shape = sp(img, det)\n",
    "                face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "                known_faces.append(np.array(face_descriptor))\n",
    "                known_names.append(person_name)\n",
    "\n",
    "        print(f\"‚úÖ ƒê√£ th√™m {person_name} v√†o danh s√°ch nh·∫≠n di·ªán.\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"‚úÖHo√†n t·∫•t nh·∫≠n di·ªán khu√¥n m·∫∑t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d833c0c",
   "metadata": {},
   "source": [
    "Nh√≥m 4\n",
    "\n",
    "D∆∞∆°ng Ng·ªçc Anh\n",
    "\n",
    "L√™ Ph√∫ H√†o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
